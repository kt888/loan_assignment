1. How long did you spend working on the problem? What did you find to be the most
difficult part?

I got the first version working in an hour. Architecting it to a production friendly so
that all criteria given in the follow up questions took time.


2. How would you modify your data model or code to account for an eventual introduction
of new, as-of-yet unknown types of covenants, beyond just maximum default likelihood
and state restrictions?
Any new constraint should be added as a constraint object in the method load_covenants.
For eg, for a new constraint should be added as follows:
	cov.add_constraint(
            Constraint('loan_attribute', <operator_type>, covenant[<name_of_constraint_in_covenants.csv>])
        )
    This will create a new_constraint attribute for Loan and ensures that the loan object satisfies
    the constraint based on the operator given.

The given constraints have been added as follows:
	cov.add_constraint(
            Constraint('default_likelihood', operator.gt, covenant['max_default_likelihood'])
        )
        cov.add_constraint(
            Constraint('state', operator.eq, covenant['banned_state'])
        )
This ensures that loan.default_likelihood < covenant['max_default_likelihood' and so on for the other constraints.



3. How would you architect your solution as a production service wherein new facilities can
be introduced at arbitrary points in time. Assume these facilities become available by the
finance team emailing your team and describing the addition with a new set of CSVs.

Description of the production service:
1. We ensure that all such new facility emails from the finance team is sent to a specific email address. E.g. facilities_update@affirm
2. We create a polling service which reads the CSV files in the emails and parses all the information available.
3. All the inserts/updates are published to a pub/sub system (E.g. Kafka). 
4. The Facilities service will be a subscriber to all the above events and will ingest the changes.


4. Your solution most likely simulates the streaming process by directly calling a method in
your code to process the loans inside of a for loop. What would a REST API look like for
this same service? Stakeholders using the API will need, at a minimum, to be able to
request a loan be assigned to a facility, and read the funding status of a loan, as well as
query the capacities remaining in facilities.


The endpoint for loans:
	POST /api/v1/loan/ -- create a loan
	GET /api/v1/loan/ -- gets all loans
	GET /api/v1/loan/<loan_id>/ -- get a particular loan with loan id
	The model schema of payload:
	 {
		  "id": "string",
		  "amount": "string",
		  "interest_rate": "string",
		  "default_liklihood": "string",
		  "state": "string"
	}

Once the endpoint has been hit, a loan object is created and the loan service tries
to assign it to a facility based on the constraints. 
	case assigned: 200, {"facility_id": ""}
	case not assigned because of capacity: 404 , {message: "Out of capacity"}
	case not assigned because of not satisfying covenant: 404 , {message: "Does not satisfy covenant <cov details>"}
	case not assigned: 422 , {message: "malformed json"}
	case not assigned: 401 , {message: "unauthorized"}


The facility endpoints will be
  GET /api/v1/facilities/ -- Get all facilities
  GET /api/v1/facilities/<facility_id> -- Get a particular facility
  PUT /api/v1/facility/<facility_id> -- Update a particular facility
  POST /api/v1/facility/ -- Create a new Facility

The loan service gets all facilities using the GET endpoint, calculates the amount remaining in the facility
and updates the facility (based on facility id) with the new amount and new yield

The POST is used to create a new Facility

The funding status of a loan can be queried using - GET /api/v1/loan/<loan_id>/
To get the information about a particular facility, query GET /api/v1/facilities/<facility_id>


5. How might you improve your assignment algorithm if you were permitted to assign loans
in batch rather than streaming? We are not looking for code here, but pseudo code or
description of a revised algorithm appreciated.

We can potentially model this problem as the minimum cost flow problem.
Here we will have M loan applications in a batch and N facilities to choose from. 
This is a bipartite graph because none of the loan nodes will have edges to each other and
none of the facilities.

In the graph, we have one node for each loan and one node for each facility.
We also create two dummy nodes, source and sink.

- We add an edge from source to each loan with capacity 1 and cost 0.
- We add an edge from each loan to each facility (only if it satisfies the covenants) with a capacity 1 
and cost (-1 * profit from loan using that facility). We use negative of profit because the algorithm minimizes
the cost of flowing through the graph.
- We add an edge from each facility to the sink.

We need to find the minimum cost flow of size M where M is the number of loan applications. We can use the
network simplex algorithm to solve this.

Reference: https://en.wikipedia.org/wiki/Minimum-cost_flow_problem


6. Because a number of facilities share the same interest rate, itâ€™s possible that there are a
number of equally appealing options by the algorithm we recommended you use
(assigning to the cheapest facility). How might you tiebreak
facilities with equal interest
rates, with the goal being to maximize the likelihood that future loans streaming in will be
assignable to some facility?

One method to break the tie is to select the facility based on the following key:
amount_owed_to_facility + interest_of_facility * loan. Every time a loan is issued
from this facility, the amount_owed_to_facility is updated. I have already implemented this.
If the optimization flag under Loan is set to True, the new method for calculating the loan is considered.
This ensures fewer ties.


